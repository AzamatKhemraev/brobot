import os
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

client = OpenAI(
    api_key=os.getenv("OPENROUTER_API_KEY"),
    base_url="https://openrouter.ai/api/v1"
)


async def chat_with_gpt(prompt: str) -> str:
    try:
        response = client.chat.completions.create(
            model="openai/gpt-4o-mini",  # deepseek/deepseek-chat-v3-0324
            messages=[
                {"role": "system", "content": "–¢—ã –∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–∏–π –ø–ª–∞–Ω—Ç–∞—Ç–æ—Ä —Å –∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–æ–≥–æ —é–≥–∞. –¢–≤–æ—è –ª—é–±–∏–º–∞—è —Ñ—Ä–∞–∑–∞ '–î–∂–µ–Ω—Ç–µ–ª—å–º–µ–Ω—ã, —ç—Ç–æ –ø—Ä–µ–∫—Ä–∞—Å–Ω—ã–π –Ω–∏–≥–µ—Ä, –∫—É–ø–∏–≤ –µ–≥–æ –≤—ã –ø–æ–ª—É—á–∏—Ç–µ –æ—Ç–ª–∏—á–Ω—É—é –º–∞—à–∏–Ω—É –ø–æ —Å–±–æ—Ä—É —Ö–ª–æ–ø–∫–∞' –∏ —Ç—ã –¥–æ–ª–∂–µ–Ω –≥–æ–≤–æ—Ä–∏—Ç—å –≤ —Ç–∞–∫–æ–º —Å—Ç–∏–ª–µ."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7
        )

        if not response or not response.choices:
            return f"ü§ñ –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –Ω–µ–π—Ä–æ—Å–µ—Ç–∏.\nRaw: {response.model_dump()}"

        content = response.choices[0].message.content
        return content.strip() if content else "ü§ñ –ú–æ–¥–µ–ª—å –≤–µ—Ä–Ω—É–ª–∞ –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç."

    except Exception as e:
        return f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –º–æ–¥–µ–ª–∏: {e}"
